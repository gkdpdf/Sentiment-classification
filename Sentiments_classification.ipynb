{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvHvFlIJtcjM"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ],
      "metadata": {
        "id": "IWyucf_PuIUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "ctOh1uxzugOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D\n"
      ],
      "metadata": {
        "id": "x6OrX_dRun9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generators\n",
        "train_ds=keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/train',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        "\n",
        ")\n",
        "\n",
        "valid_ds=keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/test',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "QZAsM-hau6ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize\n",
        "def process(image,label):\n",
        "  image=tensorflow.cast(image/255. ,tensorflow.float32)\n",
        "  return image,label\n",
        "\n",
        "train_ds=train_ds.map(process)\n",
        "valid_ds=valid_ds.map(process)"
      ],
      "metadata": {
        "id": "vCeTtppUvFQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()"
      ],
      "metadata": {
        "id": "WXxeQ-phwXAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model\n",
        "model.add(Conv2D(64,kernel_size=(3,3),activation='relu',input_shape=(256,256,3),padding='valid'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(128,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "9hKwn7wovpEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "qchu3IGowpzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "veXyTsMzw3eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_ds,validation_data=valid_ds,epochs=5)"
      ],
      "metadata": {
        "id": "MzCL0GbuxNhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "metadata": {
        "id": "zqtFzZDl0OLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])"
      ],
      "metadata": {
        "id": "6aMi9pgg0Ft4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "test_img=cv2.imread('/content/angry.jpeg')\n",
        "plt.imshow(test_img)"
      ],
      "metadata": {
        "id": "4nT5jAwFxXio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img.shape"
      ],
      "metadata": {
        "id": "SbXMCNJv0LqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img=cv2.resize(test_img,(256,256))\n",
        "plt.imshow(test_img)\n"
      ],
      "metadata": {
        "id": "0u3nSsxN0aKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input=test_img.reshape((1,256,256,3)) ##1 for input one image at one and other is shape"
      ],
      "metadata": {
        "id": "-E3a5j4U0nua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "model.predict((test_input))"
      ],
      "metadata": {
        "id": "BrqG7EzS0zOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post Data Augumentation"
      ],
      "metadata": {
        "id": "lDDmfri739Xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "n9jlaW-P01Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,            # Rescale pixel values to [0, 1]\n",
        "    rotation_range=40,         # Randomly rotate images by up to 40 degrees\n",
        "    width_shift_range=0.2,     # Randomly translate images horizontally by 20%\n",
        "    height_shift_range=0.2,    # Randomly translate images vertically by 20%\n",
        "    shear_range=0.2,           # Randomly shear images\n",
        "    zoom_range=0.2,            # Randomly zoom into images\n",
        "    horizontal_flip=True,      # Randomly flip images horizontally\n",
        "    fill_mode='nearest'        # Fill pixels after augmentations\n",
        ")\n",
        "\n",
        "# For validation data, you generally do not augment but just rescale\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "metadata": {
        "id": "02EtKt1V7ShI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/train',        # This is the target directory\n",
        "    target_size=(256, 256),     # Resize images to 150x150\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    color_mode='rgb' # Since it's binary classification\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    '/content/test',   # This is the target directory for validation data\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    color_mode='rgb'\n",
        ")\n"
      ],
      "metadata": {
        "id": "0giVttmC8FeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=5,       # Number of batches to draw from the generator per epoch\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50        # Number of batches to draw from the generator for validation\n",
        ")\n"
      ],
      "metadata": {
        "id": "wLm3-pQk8L22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the image\n",
        "img_path = '/content/happy.jpeg'  # Replace with the path to your image\n",
        "img = image.load_img(img_path, target_size=(256, 256))  # Resize to the same size as the training images\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "img_array = image.img_to_array(img)\n",
        "\n",
        "# Normalize the pixel values (rescale)\n",
        "img_array = img_array / 255.0\n",
        "\n",
        "# Add a batch dimension since the model expects batches of images\n",
        "img_array = np.expand_dims(img_array, axis=0)"
      ],
      "metadata": {
        "id": "OeYJL7nd8cvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# Since it's a binary classification problem, interpret the result\n",
        "if prediction[0] > 0.5:\n",
        "    print(f\"The image is predicted to be a happy with a probability of {prediction[0][0]:.2f}\")\n",
        "else:\n",
        "    print(f\"The image is predicted to be a angry with a probability of {1 - prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "id": "l4xwdHS7FQwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CDGHzhZuFSjP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}